\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{listings}
\usepackage{rotating, graphicx}
\usepackage{booktabs, natbib}
\usepackage[hyphens]{url}
% \usepackage [english]{babel}
\usepackage{amsmath, amsbsy, amsthm, epsfig, epsf, psfrag, graphicx,
  amssymb, enumerate, bm}
\usepackage{enumitem}

\usepackage{color}

\newcommand{\jy}[1]{\textcolor{red}{JY #1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}

\usepackage[colorlinks=true, urlcolor=blue, linkcolor=blue, citecolor=blue]{hyperref}




\newenvironment{comment}%
{\begin{quotation}\noindent\small\it\ignorespaces%
  }{\end{quotation}}



\begin{document}

\begin{center}
  {\Large\bf Response Letter to Referees' Comments}
\end{center}


\section{Summary}

We thank the Editor and the referee for their thoughtful, constructive
comments. The manuscript has been revised accordingly with the
following major changes:

\begin{enumerate}
\item
The literature review section has been revised to incorporate the work
suggested in the comments. A detailed discussion has been added to
compare the proposed method with those referred to by the editor. More
emphasis has been put on the distinctive elements of this paper, which
are the shape restrictions and the adaptability of variance in
response to either the conditional mean or marginal mean. For the
inference method, we highlighted its computational ease without
requiring a closed-form solution.
  
\item
  In the inference section, we referenced the resampling-subject
  bootstrap (RSB) method mentioned in the comments, and added a
  detailed discussion around the similarity and difference with the
  parametric bootstrap method employed in this paper. Our parametric
  bootstrap method shares the same logic as the RSB when maintaining
  the clustered structure in the data, but with a distinction -  the
  bootstrap sample is regenerated using the estimated parameters
  instead of directly from the residuals. This choice stems from
  the parametric format in our model setting.

\item
  We have added clearer details about the selection of the degree of
  freedom $K$ for the spline bases and the placement of internal
  knots. The degree of freedom $K$ will be  selected by AIC/BIC, and
  knots are evenly spaced.
\end{enumerate}


Point-by-point responses are as follows, with the reviewer/editor's comments in {\it italic}.


\section{To Referee 1}

\begin{comment}
  For a monotone function of a combination convexity and concavity for
  different interval, it seems that your method can only use
  I-splines. Is there a way to find the change points so that you
  could fit for different intervals with C-splines while preserve
  smoothness and monotonicity at the same time?
\end{comment}

This observation holds significant value and could be considered for
future exploration. In our simulation study, the third setting
(function $g_3$) has intervals with both convex and concave
patterns. While we solely employed monotone restrictions for this
scenario, there's potential for improved estimation by incorporating
the detection of change points.  We have added a comment to the end of
the last paragraph of Section 6.


\begin{comment}
  Variances near boundaries are typically larger than that in the
  middle of a growth curve. The monotone restriction may
  increase/decrease the estimate of variance near a boundary. How do
  you control this?
\end{comment}

Indeed this is a valid and valuable point for GCA. Our paper focused
more on the situation that variance near one end of the boundary is
larger. It can be the next step work to enable larger variance on both ends
of the boundaries. We updated the writing in the second and fifth paragraph of
Section~1 to emphasize that this is what motivated us to propose this
method, and updated the last paragraph of Discussion section to
include future work.


\section{To Referee 2}

\begin{comment}
  1. The general setup as described in Section 2 appears to be very
  close to the ones in \cite{rice2001nonparametric} and,
  for that matter, the models of \cite{huang2002varying,
    huang2004polynomial}. Also, see the
  relevant chapters in the the book \cite{wu2018nonparametric}. The
  only difference is the M-splines, I-splines, C-splines, etc., as
  opposed to the usual B-splines. To clearly state the objective of
  the paper, it is better to state the overall model before the spline
  basis expressions. You need to inform the reader which functions
  should be approximated by splines, why M-splines, I-splines,
  C-splines, etc. are needed, and pros and cons of these base
  choices. For clarity, please also state and justify the similarities
  and differences from the usual polynomial splines (see
  \cite{wu2018nonparametric}).
\end{comment}

The literature highlighted by the editor holds great relevance to our
work, prompting us to enhance the literature review. We updated the
third paragraph of Section 1, the first and second paragraphs of
Section 2 to include the following change: literatures were added to
include past work around using splines on clustered or longitudinal
data~\cite{rice2001nonparametric, huang2002varying,
  huang2004polynomial, wu2018nonparametric}. We also added more
emphasis to make it clear that the noval part of this paper is the
shape restrictions on both mean and variation terms. Please see the
fifth paragraph of Section~1.


\begin{comment}
  2. Section 3.1: Model (3.1) appears to be a usual LME with some
  basis variance functions. This setup is more restrictive compared to
  the ones in \cite{rice2001nonparametric} or \cite{huang2002varying} or the
  models in \cite{wu2018nonparametric}. In addition, the authors did not
  specify $K$ to be dependent on the sample size $n$. For growth curves
  (the topic of the paper), a classical LME is clearly not
  appropriate. It will be more interesting and relevant if $\beta$ is
  allowed to be a function of $t$. It will dramatically reduce the
  value of this paper if your general setup is a standard LME
  (3.1). In addition, growth curves in practice, such as children's
  growth, e.g. height, weight, body mass index, blood pressure and
  cholesterol, over age, may not be a linear model, and is more
  appropriate to be nonparametric. I actually think that you can
  remove this subsection completely and do straight to the
  longitudinal data case in Section 3.2.
\end{comment}


It is a great point that clustered data is the more prevalent scenario
in GCA, and starting with the independent data and model in this paper
might be confusing. We updated the first and second paragraphs of
Section 3 to add more clarity on the reason to include independent
data scenario: the main focus is to use shape restrictions on GCA, and
we want the paper to be thorough and covers both scenarios since
certain shape restrictions may occur to either of them. This
perspective is also reflected in the pancrea data analysis presented
in Section~5.1.


It is important to acknowledge that the mean pattern of GCA is not
linear with time. We added a second paragraph of Section 3.1 to show
it more clearly that the spline bases of time should be used in the
mean model. The inference process won't change when getting the
coefficient estimation of coefficients of spline bases, and the model
selection method to choose the degree and degree of freedom of spline
bases are the same as for the error variance.


Regarding the spline bases, the degree of freedom $K$ will be chosen
using the model selection method outlined in Section 3.4. We updated
section 3.1 and 3.2 to emphasize this when we first introduced
$K$. Additionally, we've made updates to the first and second
paragraphs of Section 3.4, underscoring that the choice of $K$ should
adapt with the sample size, both overall ($n$) and within clusters
($n_i$).


Recognizing the valuable consideration of permitting the coefficient
$\beta$ to evolve with time in GCA, our model
is designed to effectively manage this scenario. This can be accomplished
through the incorporation of interaction terms between covariates and
the spline bases of time within the mean function. We updated the
last paragraphs of Section 3.1 and 3.2 to reflect this,
with the two references cited~\citep{huang2002varying,
  huang2004polynomial}.

\begin{comment}
  3. Section 3.2: It is better to start with the framework
  here. Section 3.1 adds little value, and may be removed to make the
  paper more succinct.
\end{comment}

Please refer to the response to comment 2, first paragraph.


\begin{comment}
  4. Sections 3.1 $\&$ 3.2: You need to define your data clearly. Such
  as, what are ${\bf Y}_i$, ${\bf t}_i$, etc.? It is better to define
  the structure of your data at the beginning of this section. The
  number of repeated measurements $n_i$ may or may not be the same for
  each subject $i$, and $n_i$ may or may not be large. You need to
  make all these assumptions clear and reasonable for your real data
  examples.
\end{comment}

In consideration of valuable feedback, we've made adjustments
to the writing to improve the clarity surrounding data definitions
and notations. Kindly refer to the refined explanations in the first
paragraphs of both Section 3.1 and 3.2. Furthermore, we have updated
the notations in model (3.2) to provide a clearer depiction of the
underlying settings.


\begin{comment}
  5. Algorithm 1, page 4: \cite{huang2002varying, huang2004polynomial}
  used OLS or weight adjusted by $n$ and $n_i$ (see,
  \cite{wu2018nonparametric}, Section 9.2). Is your iterative
  Algorithm 1 better than the OLS or weighted LS of Huang, Lan and Wu?
\end{comment}

This is a very helpful point to make our discussion more
thorough. We've revisited the writing to provide clearer explanations for using
the iterative algorithm, as outlined in the first paragraph of
Section 3.3. The primary rationale behind this choice lies in the
simplicity and efficiency of computation, avoiding the need for
intricate closed-form solutions. This method exhibits flexibility and
ease of application across various scenarios, particularly in cases
where deriving closed-form solutions proves challengingâ€”such as
situations when error variance changes with conditional or
marginal mean.


\begin{comment}
  6. Equation (3.2) of page 4: Same as above, this model is a slight
  generalization of the classical LME, and is very restrictive and may
  not be appropriate for growth curves. Only adding a basis function
  with fixed $K$ for variance is not sufficient. You need to consider
  a more practical model that people can justify. In my view, a
  generalization of the setup of \cite{huang2002varying} with basis
  approximated variances is a more relevant and interesting model.
\end{comment}

Please see the detailed response to comment~1 and~2. We've updated the
manuscript according to the valuable comments to make the discussion
more thorough and solid.


\begin{comment}
7. Section 3.3: The likelihood based inference, although popular, is
not suitable for spline based models, because you really should allow
$K$ to change with your sample, i.e. $n$ and $n_i$. Existing
inferences, such as \cite{huang2002varying} and \cite{wu2018nonparametric}
used "resampling-subject bootstrap" (RSB) inferences. I wonder how
your Algorithm 2 is compared with the "resampling-subject bootstrap."
It appears that the RSB can be more generally applied. In any case,
you need to justify the use of your algorithm over the RSB.
\end{comment}


It is a great point that we should compare the proposed parametric
bootstrap method with the RSB in existing literature, since they share
a lot of similarities. We updated the second paragraph of Section 3.3
to include the comparison in writing. The key distinction lies in
generating the bootstrapped error term using the estimated parameters
instead of residuals. This is due to our ability
to estimate the error variance using spline bases.


\begin{comment}
  8. Section 3.4: The use of AIC and BIC appears to be a
  generalization of the ones in \cite{rice2001nonparametric}. You
  may need to clarify what is novel in your setting here.
\end{comment}

It is a valuable point that we should cite past works that uses same
method as a support. We updated the first and second paragraphs of
Section 3.4 to show that the AIC and BIC criteria align with the
framework presented in \cite{rice2001nonparametric}. The only
difference is when numerical integration becomes necessary for certain
scenarios when closed-form integration is unavailable.


\begin{comment}
  9. It is not clear how the numbers and locations of the knots are
  selected. In \cite{rice2001nonparametric}, \cite{huang2002varying},
  and \cite{wu2018nonparametric}, the splines are selected by
  'deleting subject cross validation.' Please provide a procedure for
  smoothing parameter selection here.
\end{comment}

We appreciate the comment and incorporate it to add more clarity on
the writing. In the update to Section 3.4, we've placed
additional emphasis on the selection of knots, drawing a
comparison with the 'deleting subject cross-validation' method as
detailed in the paper by \cite{rice2001nonparametric}. Furthermore,
we've revisited the paragraphs discussing Model (3.1) and Model (3.2)
to underscore that the choice of $K$ should be made through the model
selection method outlined in Section 3.4.


\begin{comment}
  10. Simulation: I am fine with your simulation. But, you may want to
  remove Section 4.1 for the i.i.d. data case, and change the setting
  to a more general model in Section 2. The LME data case is really
  not adding anything new to the literature. In particular, you should
  not assume the number of spline terms $K$ to be fixed. In practice,
  it should be selected.
\end{comment}

Please see the response to comment~1 and comment~2.


\begin{comment}
  11. Section 5: Please give a clear but brief description of the
  datasets, including citing the studies, whether the data is
  available, how to obtain the data, etc. We want to make sure that
  the information (data and publications) is available to our readers
  and the biomedical conclusion is meaningful.
\end{comment}

Additional information has been incorporated into the second paragraph
of Section~5.1 and the first paragraph of Section~5.2.

\begin{comment}
  12. Section~5.1, equation for fetal pancreas length: How do you
  select the number and location of the knots for $t$? What is your
  justification? It appears that you used BIC to select $K_1$ and
  $K_2$. What are the medical implications and conclusions of your
  study? What new information does your study provide as opposed to
  the published results?
\end{comment}

Please see the response to comment~2.

 
\begin{comment}
  13. The comments above, $\#$12, also apply to the "Chicken Weight"
  example of Section~5.2.
\end{comment}

In the updated manuscript, we've extended the discussion in the final
paragraph of Section~5.2 to include further insights regarding the
incorporation of new values in real-life scenarios.


\begin{comment}
  14. It will be helpful to add an appendix with R code. It will be
  tremendously helpful to our readers. 
\end{comment}

The R code is available on a public github repo, and the link is
provided in the Section~1 Introduction. 




\bibliographystyle{chicago}
\bibliography{growth}

%\atColsBreak{\pagediscards}
\end{document}
